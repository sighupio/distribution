# API server
- query: histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{component="apiserver", verb!~"WATCH"}[2m])) by (verb,resource,instance,le)) > 0
  metricName: API99thLatency

- query: sum(irate(apiserver_request_total{component="apiserver", verb!="WATCH",subresource!="log"}[2m])) by (verb,resource,component,code)
  metricName: APIRequestRate

- query: sum(apiserver_current_inflight_requests{}) by (request_kind) > 0
  metricName: APIInflightRequests

# Kubelet metrics
- query: sum(irate(process_cpu_seconds_total{service="kubelet",job="kubelet"}[2m]) * 100) by (node) and on (node) kube_node_role{role="worker"}
  metricName: KubeletCPU-AggregatedWorkers

- query: sum(process_resident_memory_bytes{service="kubelet",job="kubelet"}) by (node) and on (node) kube_node_role{role="worker"}
  metricName: KubeletMemory-AggregatedWorkers

# Container & pod metrics
- query: (sum(container_memory_rss{name!="",container!="POD"}) by (container, pod, namespace, node) and on (node) kube_node_role{role="master"}) > 0
  metricName: containerMemory-Masters

- query: (sum(irate(container_cpu_usage_seconds_total{name!="",container!="POD"}[2m]) * 100) by (container, pod, namespace, node) and on (node) kube_node_role{role="master"}) > 0
  metricName: containerCPU-Masters

- query: (sum(irate(container_cpu_usage_seconds_total{pod!="",container="prometheus",namespace="monitoring"}[2m]) * 100) by (container, pod, namespace, node) and on (node) kube_node_role{role="infra"}) > 0
  metricName: containerCPU-Prometheus

- query: (avg(irate(container_cpu_usage_seconds_total{name!="",container!="POD",namespace="ingress-nginx"}[2m]) * 100 and on (node) kube_node_role{role="infra"}) by (namespace, container)) > 0
  metricName: containerCPU-AggregatedWorkers

- query: (avg(irate(container_cpu_usage_seconds_total{name!="",container!="POD",namespace=~"(ingress-nginx|monitoring|logging)"}[2m]) * 100 and on (node) kube_node_role{role="infra"}) by (namespace, container)) > 0
  metricName: containerCPU-AggregatedInfra

- query: (sum(container_memory_rss{pod!="",namespace="monitoring",name!="",container="prometheus"}) by (container, pod, namespace, node) and on (node) kube_node_role{role="infra"}) > 0
  metricName: containerMemory-Prometheus

- query: avg(container_memory_rss{name!="",container!="POD",namespace="ingress-nginx"} and on (node) kube_node_role{role="worker"}) by (container, namespace)
  metricName: containerMemory-AggregatedWorkers

- query: avg(container_memory_rss{name!="",container!="POD",namespace=~"(ingress-nginx|monitoring|logging)"} and on (node) kube_node_role{role="infra"}) by (container, namespace)
  metricName: containerMemory-AggregatedInfra

# Node metrics
- query: (sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")) > 0
  metricName: nodeCPU-Masters

- query: (avg((sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))) by (mode)) > 0
  metricName: nodeCPU-AggregatedWorkers

- query: (avg((sum(irate(node_cpu_seconds_total[2m])) by (mode,instance) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)"))) by (mode)) > 0
  metricName: nodeCPU-AggregatedInfra

- query: avg(node_memory_MemAvailable_bytes) by (instance) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeMemoryAvailable-Masters

- query: avg(node_memory_MemAvailable_bytes and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryAvailable-AggregatedWorkers

- query: avg(node_memory_MemAvailable_bytes and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryAvailable-AggregatedInfra

- query: avg(node_memory_Active_bytes) by (instance) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeMemoryActive-Masters

- query: avg(node_memory_Active_bytes and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryActive-AggregatedWorkers

- query: avg(avg(node_memory_Active_bytes) by (instance) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryActive-AggregatedInfra

- query: avg(node_memory_Cached_bytes) by (instance) + avg(node_memory_Buffers_bytes) by (instance) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeMemoryCached+nodeMemoryBuffers-Masters

- query: avg(node_memory_Cached_bytes + node_memory_Buffers_bytes and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryCached+nodeMemoryBuffers-AggregatedWorkers

- query: avg(node_memory_Cached_bytes + node_memory_Buffers_bytes and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)"))
  metricName: nodeMemoryCached+nodeMemoryBuffers-AggregatedInfra

- query: irate(node_network_receive_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: rxNetworkBytes-Masters

- query: avg(irate(node_network_receive_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: rxNetworkBytes-AggregatedWorkers

- query: avg(irate(node_network_receive_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: rxNetworkBytes-AggregatedInfra

- query: irate(node_network_transmit_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: txNetworkBytes-Masters

- query: avg(irate(node_network_transmit_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: txNetworkBytes-AggregatedWorkers

- query: avg(irate(node_network_transmit_bytes_total{device=~"^(ens|enp|eth|bond|team).*"}[2m]) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: txNetworkBytes-AggregatedInfra

- query: rate(node_disk_written_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeDiskWrittenBytes-Masters

- query: avg(rate(node_disk_written_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: nodeDiskWrittenBytes-AggregatedWorkers

- query: avg(rate(node_disk_written_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: nodeDiskWrittenBytes-AggregatedInfra

- query: rate(node_disk_read_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="master"}, "instance", "$1", "node", "(.+)")
  metricName: nodeDiskReadBytes-Masters

- query: avg(rate(node_disk_read_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="worker"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: nodeDiskReadBytes-AggregatedWorkers

- query: avg(rate(node_disk_read_bytes_total{device!~"^(dm|rb).*"}[2m]) and on (instance) label_replace(kube_node_role{role="infra"}, "instance", "$1", "node", "(.+)")) by (device)
  metricName: nodeDiskReadBytes-AggregatedInfra

# Etcd metrics
- query: sum(rate(etcd_server_leader_changes_seen_total[2m]))
  metricName: etcdLeaderChangesRate

- query: etcd_server_is_leader > 0
  metricName: etcdServerIsLeader

- query: histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket[2m]))
  metricName: 99thEtcdDiskBackendCommitDurationSeconds

- query: histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket[2m]))
  metricName: 99thEtcdDiskWalFsyncDurationSeconds

- query: histogram_quantile(0.99, rate(etcd_network_peer_round_trip_time_seconds_bucket[5m]))
  metricName: 99thEtcdRoundTripTimeSeconds

- query: etcd_mvcc_db_total_size_in_bytes
  metricName: etcdDBPhysicalSizeBytes

- query: etcd_mvcc_db_total_size_in_use_in_bytes
  metricName: etcdDBLogicalSizeBytes

- query: sum by (cluster_version)(etcd_cluster_version)
  metricName: etcdVersion
  instant: true

- query: sum(rate(etcd_lease_object_counts_sum{}[5m])) by (resource) > 0
  metricName: etcdObjectCount

- query: histogram_quantile(0.99,sum(rate(etcd_request_duration_seconds_bucket[2m])) by (le,operation,apiserver)) > 0
  metricName: P99APIEtcdRequestLatency

# Cluster metrics
- query:  sum(kube_namespace_status_phase) by (phase) > 0
  metricName: namespaceCount

- query: sum(kube_pod_status_phase{}) by (phase)
  metricName: podStatusCount

- query: count(kube_secret_info{})
  metricName: secretCount

- query: count(kube_deployment_spec_replicas{})
  metricName: deploymentCount

- query: count(kube_configmap_info{})
  metricName: configmapCount

- query: count(kube_service_info{})
  metricName: serviceCount

# - query: count(openshift_route_created{})
  # metricName: routeCount
  # instant: true

- query: kube_node_role
  metricName: nodeRoles
  instant: true

- query: sum(kube_node_status_condition{status="true"}) by (condition)
  metricName: nodeStatus

- query: (sum(rate(container_fs_writes_bytes_total{container!="",device!~".+dm.+"}[5m])) by (device, container, node) and on (node) kube_node_role{role="master"}) > 0
  metricName: containerDiskUsage

- query: sum(kube_node_info) by (kubelet_version)
  metricName: clusterVersion
  instant: true

# Golang metrics

- query: go_memstats_heap_alloc_bytes{job=~"apiserver|api|etcd"}
  metricName: goHeapAllocBytes

- query: go_memstats_heap_inuse_bytes{job=~"apiserver|api|etcd"}
  metricName: goHeapInuseBytes

- query: go_gc_duration_seconds{job=~"apiserver|api|etcd",quantile="1"}
  metricName: goGCDurationSeconds
